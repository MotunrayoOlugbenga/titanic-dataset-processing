{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "im=Imputer\n",
    "train['Cabin']=im.fit_transform( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Cabin'].fillna(train['Cabin'].mode()[0],inplace=True)\n",
    "train['Embarked'].fillna(train['Embarked'].mode()[0],inplace=True)\n",
    "train['Age'].fillna(train['Age'].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb=LabelEncoder()\n",
    "train['Cabin']=lb.fit_transform(train['Cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "a.append(np.array(train['Age'])/np.array(train['Pclass']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 7.33333333, 38.        ,  8.66666667, 35.        , 11.66666667,\n",
       "         8.        , 54.        ,  0.66666667,  9.        ,  7.        ,\n",
       "         1.33333333, 58.        ,  6.66666667, 13.        ,  4.66666667,\n",
       "        27.5       ,  0.66666667, 12.        , 10.33333333,  8.        ,\n",
       "        17.5       , 17.        ,  5.        , 28.        ,  2.66666667,\n",
       "        12.66666667,  8.        , 19.        ,  8.        ,  8.        ,\n",
       "        40.        , 24.        ,  8.        , 33.        , 28.        ,\n",
       "        42.        ,  8.        ,  7.        ,  6.        ,  4.66666667,\n",
       "        13.33333333, 13.5       ,  8.        ,  1.5       ,  6.33333333,\n",
       "         8.        ,  8.        ,  8.        ,  8.        ,  6.        ,\n",
       "         2.33333333,  7.        , 49.        , 14.5       , 65.        ,\n",
       "        24.        , 10.5       ,  9.5       ,  2.5       ,  3.66666667,\n",
       "         7.33333333, 38.        , 45.        ,  1.33333333, 24.        ,\n",
       "         8.        , 14.5       ,  6.33333333,  5.66666667,  8.66666667,\n",
       "        16.        ,  5.33333333, 10.5       ,  8.66666667, 10.66666667,\n",
       "         8.33333333,  8.        ,  8.        ,  0.415     , 10.        ,\n",
       "         7.33333333,  9.66666667,  8.        , 28.        ,  8.5       ,\n",
       "        11.        ,  5.33333333,  8.        , 23.        ,  8.        ,\n",
       "         9.66666667,  6.66666667, 46.        ,  8.66666667, 19.66666667,\n",
       "         8.        , 71.        , 23.        , 17.        , 17.        ,\n",
       "         9.33333333,  8.        , 21.        , 11.        , 12.33333333,\n",
       "         9.33333333,  7.        ,  8.        , 12.66666667,  8.        ,\n",
       "        47.        ,  4.83333333,  7.33333333,  6.66666667,  5.66666667,\n",
       "         7.        , 23.5       , 14.5       , 24.        ,  0.66666667,\n",
       "        10.5       ,  8.        , 16.25      , 16.25      , 54.        ,\n",
       "         4.        ,  8.        ,  8.        ,  8.        , 15.        ,\n",
       "        11.        ,  6.66666667, 15.66666667, 14.5       , 12.5       ,\n",
       "        11.5       , 19.        , 37.        ,  5.33333333, 24.        ,\n",
       "         8.        ,  7.33333333,  8.        ,  6.33333333,  9.        ,\n",
       "         9.5       ,  9.        ,  3.        , 18.25      , 21.        ,\n",
       "        25.5       , 22.        , 18.5       , 13.5       ,  8.        ,\n",
       "        51.        ,  5.33333333, 10.        ,  8.        ,  8.        ,\n",
       "        14.66666667, 20.        ,  8.66666667,  5.66666667,  0.33333333,\n",
       "         3.        , 24.        , 15.        , 24.        ,  9.33333333,\n",
       "        61.        ,  1.33333333,  0.33333333,  7.        , 56.        ,\n",
       "         6.        ,  8.        , 50.        , 15.        , 12.        ,\n",
       "         8.        , 12.        ,  3.        ,  0.5       ,  1.33333333,\n",
       "        24.        ,  8.        , 45.        , 13.33333333, 12.        ,\n",
       "        16.        ,  9.5       ,  6.33333333,  1.5       , 44.        ,\n",
       "        58.        ,  8.        , 14.        ,  8.        , 12.        ,\n",
       "         9.33333333,  8.        , 11.33333333, 15.16666667,  6.        ,\n",
       "         0.66666667, 10.66666667,  8.66666667,  5.33333333, 40.        ,\n",
       "         8.        , 17.5       ,  7.33333333, 15.        ,  8.        ,\n",
       "        31.        ,  9.        , 21.        , 32.        , 15.        ,\n",
       "         5.33333333, 13.5       , 17.        ,  8.        , 38.        ,\n",
       "         7.33333333,  9.5       ,  6.83333333,  9.        ,  8.        ,\n",
       "        35.        ,  9.66666667, 29.5       ,  1.66666667, 12.        ,\n",
       "         8.        , 22.        ,  4.        ,  9.5       , 16.5       ,\n",
       "         8.        ,  8.        , 14.5       ,  7.33333333, 10.        ,\n",
       "        44.        ,  8.33333333, 12.        , 37.        , 27.        ,\n",
       "         8.        ,  9.66666667, 62.        , 10.        , 13.66666667,\n",
       "         9.66666667, 24.        , 30.        , 35.        , 25.        ,\n",
       "         8.        ,  1.        , 52.        , 40.        ,  8.        ,\n",
       "        18.        ,  5.33333333,  8.33333333, 58.        , 35.        ,\n",
       "        24.        ,  8.33333333, 20.5       , 37.        ,  8.        ,\n",
       "        63.        , 15.        , 12.        ,  2.33333333, 11.66666667,\n",
       "        21.66666667,  9.33333333,  5.33333333,  6.33333333, 24.        ,\n",
       "        11.        , 10.        ,  7.33333333, 21.        ,  7.33333333,\n",
       "        26.        , 19.        , 18.        ,  8.        ,  8.        ,\n",
       "        24.        ,  7.83333333,  2.        , 24.        , 50.        ,\n",
       "         8.        ,  8.        ,  6.33333333, 12.        ,  8.        ,\n",
       "         0.92      , 24.        , 17.        , 15.        , 30.        ,\n",
       "        24.        , 18.        , 13.        ,  9.33333333, 21.5       ,\n",
       "         8.66666667, 12.        , 27.        , 31.        , 40.        ,\n",
       "         7.33333333,  9.        , 15.        , 11.        ,  8.        ,\n",
       "        36.        , 20.33333333, 18.        , 10.33333333, 16.        ,\n",
       "         8.        , 45.5       , 38.        ,  5.33333333, 24.        ,\n",
       "         8.        , 29.        , 41.        , 15.        , 45.        ,\n",
       "         1.        , 24.        , 14.        , 12.5       , 18.        ,\n",
       "        12.        , 20.        ,  8.        ,  1.        , 14.        ,\n",
       "         7.66666667, 24.        ,  5.        ,  8.33333333,  8.        ,\n",
       "         9.33333333, 22.        , 19.        ,  8.        ,  8.        ,\n",
       "        13.33333333, 14.5       , 15.        , 11.66666667,  8.        ,\n",
       "        10.        , 60.        ,  8.        ,  8.        , 24.        ,\n",
       "        25.        ,  6.        ,  6.33333333, 22.        ,  1.        ,\n",
       "        24.        ,  7.33333333, 27.        ,  6.66666667,  6.33333333,\n",
       "        42.        ,  0.33333333, 10.66666667, 35.        ,  8.        ,\n",
       "         9.        ,  0.33333333, 18.        ,  8.        ,  8.5       ,\n",
       "        36.        ,  7.        ,  9.33333333, 23.        ,  8.        ,\n",
       "         7.33333333, 10.33333333, 23.        , 11.5       , 14.        ,\n",
       "        13.        ,  8.66666667,  7.        ,  9.33333333,  6.66666667,\n",
       "        17.        , 17.        ,  1.5       ,  7.        ,  8.        ,\n",
       "         8.        ,  8.        , 33.        , 12.        , 14.66666667,\n",
       "         8.        , 17.        ,  9.        , 15.        ,  3.33333333,\n",
       "         8.        ,  7.        ,  9.66666667,  9.33333333,  6.        ,\n",
       "         8.        , 14.        ,  9.5       ,  8.        , 10.66666667,\n",
       "        28.        ,  8.        , 21.        ,  5.66666667, 50.        ,\n",
       "        14.        ,  7.        , 12.        , 64.        , 15.5       ,\n",
       "        22.5       ,  6.66666667,  8.33333333, 14.        ,  8.        ,\n",
       "         4.        ,  6.5       , 34.        ,  1.66666667, 52.        ,\n",
       "        18.        ,  8.        , 30.        , 49.        ,  8.        ,\n",
       "         9.66666667, 65.        , 24.        , 25.        ,  8.        ,\n",
       "        48.        , 11.33333333, 47.        , 24.        ,  8.        ,\n",
       "        12.66666667, 12.        , 56.        ,  8.        ,  0.25      ,\n",
       "         8.        , 12.66666667, 16.5       , 11.5       ,  7.33333333,\n",
       "        24.        , 17.        ,  9.66666667,  7.33333333,  0.66666667,\n",
       "         3.        , 12.        , 16.66666667, 21.        , 25.        ,\n",
       "         8.        , 35.        , 58.        , 10.        ,  3.        ,\n",
       "         8.        ,  7.        , 55.        , 71.        ,  7.        ,\n",
       "         8.        , 54.        ,  8.        , 25.        ,  8.        ,\n",
       "         5.66666667,  7.        ,  8.        , 12.33333333, 16.        ,\n",
       "        18.        , 16.5       , 24.        ,  9.33333333,  8.66666667,\n",
       "         9.66666667,  8.        , 36.        , 54.        ,  8.        ,\n",
       "        47.        , 17.        ,  8.        , 18.        , 10.66666667,\n",
       "        30.        ,  7.33333333,  8.        , 44.        ,  8.        ,\n",
       "        13.5       , 25.        , 24.        , 13.        , 11.5       ,\n",
       "         1.        ,  8.        ,  5.66666667,  8.        , 10.        ,\n",
       "         3.5       , 45.        , 30.        ,  8.        , 22.        ,\n",
       "        36.        ,  3.        ,  3.66666667, 16.        , 50.        ,\n",
       "        64.        ,  9.5       , 12.        , 11.        ,  4.        ,\n",
       "        17.        , 13.5       ,  8.        ,  7.33333333,  7.33333333,\n",
       "        62.        , 48.        , 24.        , 39.        , 12.        ,\n",
       "         8.        , 13.33333333, 14.        ,  8.        ,  8.        ,\n",
       "         8.        ,  6.33333333,  9.66666667,  8.        , 10.66666667,\n",
       "        31.        , 53.        , 36.        ,  8.        ,  5.33333333,\n",
       "         6.33333333, 17.        , 39.        ,  8.        , 10.66666667,\n",
       "        12.5       , 39.        , 27.        , 36.        ,  8.        ,\n",
       "        18.        , 23.5       , 60.        ,  7.33333333,  8.        ,\n",
       "        11.66666667, 52.        , 15.66666667,  8.        , 18.5       ,\n",
       "        12.        , 12.        , 16.33333333,  8.        , 49.        ,\n",
       "        12.        ,  8.        , 24.        , 14.66666667, 35.        ,\n",
       "        12.        , 10.        , 27.        , 11.        , 40.        ,\n",
       "        13.        ,  8.        ,  8.        ,  8.        , 11.66666667,\n",
       "        12.        , 11.33333333,  8.66666667,  2.        , 13.        ,\n",
       "         9.        , 42.        ,  6.66666667,  7.        ,  7.        ,\n",
       "        61.        , 28.5       , 21.        ,  8.66666667,  8.        ,\n",
       "        80.        , 17.        , 32.        , 24.        ,  3.        ,\n",
       "        14.        , 10.66666667, 15.5       , 13.66666667,  8.        ,\n",
       "         6.66666667, 24.        ,  0.66666667,  8.        ,  0.25      ,\n",
       "        48.        ,  6.33333333, 56.        ,  8.        ,  7.66666667,\n",
       "         8.        ,  9.        ,  7.        ,  8.        ,  6.        ,\n",
       "        12.        ,  8.        , 10.66666667, 11.5       , 58.        ,\n",
       "        50.        , 13.33333333, 47.        , 12.        ,  6.66666667,\n",
       "        16.        , 12.5       ,  8.        , 14.33333333, 24.        ,\n",
       "        20.        , 31.        , 35.        , 15.5       , 12.        ,\n",
       "         6.        ,  8.16666667,  6.        , 14.33333333, 36.        ,\n",
       "         8.        , 27.        ,  6.66666667,  4.66666667, 30.        ,\n",
       "        12.5       ,  4.66666667,  6.33333333,  6.        , 15.        ,\n",
       "        31.        ,  1.33333333,  8.        ,  8.33333333, 60.        ,\n",
       "        26.        , 14.66666667,  8.        , 49.        , 14.        ,\n",
       "        18.        , 35.        ,  6.        ,  8.33333333,  8.66666667,\n",
       "        19.5       , 22.5       , 42.        , 22.        ,  8.        ,\n",
       "        24.        , 24.        , 48.        ,  9.66666667, 26.        ,\n",
       "         6.33333333, 38.        , 13.5       ,  8.        , 11.        ,\n",
       "         3.        ,  5.66666667, 17.        , 25.        , 27.        ,\n",
       "         6.66666667, 15.        ,  8.        , 12.5       ,  8.33333333,\n",
       "        29.        ,  3.66666667, 12.        , 11.5       , 11.5       ,\n",
       "         9.5       , 16.        , 35.        ,  8.        ,  8.        ,\n",
       "        24.        , 36.        , 21.        ,  8.        , 10.33333333,\n",
       "        70.        ,  5.33333333, 15.        , 19.        , 10.33333333,\n",
       "         2.        ,  2.        , 11.        ,  7.66666667, 24.        ,\n",
       "         0.335     ,  9.33333333,  9.        , 11.33333333, 33.        ,\n",
       "         8.        , 13.66666667,  6.66666667, 36.        ,  5.33333333,\n",
       "        51.        , 24.        , 10.16666667,  8.        , 10.66666667,\n",
       "         8.        , 16.        , 28.5       ,  8.        , 27.        ,\n",
       "         6.        ,  8.        ,  1.66666667,  8.        , 43.        ,\n",
       "         4.33333333, 17.        , 29.        ,  8.        ,  8.33333333,\n",
       "         8.33333333,  6.        ,  2.66666667,  0.33333333, 46.        ,\n",
       "         8.        ,  8.        ,  8.        , 24.        ,  8.33333333,\n",
       "        19.5       , 49.        , 10.33333333, 10.        , 10.        ,\n",
       "        17.        , 15.5       , 11.        ,  0.14      ,  9.        ,\n",
       "        10.33333333, 39.        ,  6.        , 19.5       , 33.        ,\n",
       "         8.66666667, 13.        , 17.5       ,  2.        , 10.16666667,\n",
       "        24.        ,  7.66666667, 15.5       , 14.33333333,  3.33333333,\n",
       "        52.        ,  9.        , 38.        ,  9.        ,  0.66666667,\n",
       "         8.        ,  8.        ,  0.5       ,  8.        , 62.        ,\n",
       "         5.        ,  0.415     ,  8.        ,  7.66666667,  6.        ,\n",
       "        39.        ,  7.        ,  8.        , 10.66666667, 24.        ,\n",
       "         6.66666667,  8.        , 30.        , 11.5       ,  5.66666667,\n",
       "        14.        ,  8.        , 11.66666667, 14.        , 24.        ,\n",
       "         1.33333333, 24.66666667,  3.        , 16.        , 22.        ,\n",
       "         6.        , 45.        , 51.        ,  8.        ,  8.        ,\n",
       "        13.66666667, 10.5       , 48.        ,  8.        , 12.        ,\n",
       "        21.        , 13.5       , 31.        ,  8.        ,  1.33333333,\n",
       "         8.66666667, 47.        , 33.        , 15.66666667, 14.        ,\n",
       "         5.        ,  6.66666667,  6.33333333,  8.        , 56.        ,\n",
       "        12.5       , 11.        ,  7.33333333, 14.        ,  8.33333333,\n",
       "        13.        , 13.5       , 19.        ,  8.        , 26.        ,\n",
       "        10.66666667])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zip argument #1 must support iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-824695c46520>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclas\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Age'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Pclass'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdiv2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclas\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mdiv2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mage\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mclas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdiv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiv2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: zip argument #1 must support iteration"
     ]
    }
   ],
   "source": [
    "div1=[]\n",
    "for age,clas in zip(train['Age'],train['Pclass']):\n",
    "    div2=[]\n",
    "    for age,clas in zip(age,clas):\n",
    "        div2=age/clas\n",
    "div1.append(div2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.0\n",
      "38.0\n",
      "26.0\n",
      "35.0\n",
      "35.0\n",
      "24.0\n",
      "54.0\n",
      "2.0\n",
      "27.0\n",
      "14.0\n",
      "4.0\n",
      "58.0\n",
      "20.0\n",
      "39.0\n",
      "14.0\n",
      "55.0\n",
      "2.0\n",
      "24.0\n",
      "31.0\n",
      "24.0\n",
      "35.0\n",
      "34.0\n",
      "15.0\n",
      "28.0\n",
      "8.0\n",
      "38.0\n",
      "24.0\n",
      "19.0\n",
      "24.0\n",
      "24.0\n",
      "40.0\n",
      "24.0\n",
      "24.0\n",
      "66.0\n",
      "28.0\n",
      "42.0\n",
      "24.0\n",
      "21.0\n",
      "18.0\n",
      "14.0\n",
      "40.0\n",
      "27.0\n",
      "24.0\n",
      "3.0\n",
      "19.0\n",
      "24.0\n",
      "24.0\n",
      "24.0\n",
      "24.0\n",
      "18.0\n",
      "7.0\n",
      "21.0\n",
      "49.0\n",
      "29.0\n",
      "65.0\n",
      "24.0\n",
      "21.0\n",
      "28.5\n",
      "5.0\n",
      "11.0\n",
      "22.0\n",
      "38.0\n",
      "45.0\n",
      "4.0\n",
      "24.0\n",
      "24.0\n",
      "29.0\n",
      "19.0\n",
      "17.0\n",
      "26.0\n",
      "32.0\n",
      "16.0\n",
      "21.0\n",
      "26.0\n",
      "32.0\n",
      "25.0\n",
      "24.0\n",
      "24.0\n",
      "0.83\n",
      "30.0\n",
      "22.0\n",
      "29.0\n",
      "24.0\n",
      "28.0\n",
      "17.0\n",
      "33.0\n",
      "16.0\n",
      "24.0\n",
      "23.0\n",
      "24.0\n",
      "29.0\n",
      "20.0\n",
      "46.0\n",
      "26.0\n",
      "59.0\n",
      "24.0\n",
      "71.0\n",
      "23.0\n",
      "34.0\n",
      "34.0\n",
      "28.0\n",
      "24.0\n",
      "21.0\n",
      "33.0\n",
      "37.0\n",
      "28.0\n",
      "21.0\n",
      "24.0\n",
      "38.0\n",
      "24.0\n",
      "47.0\n",
      "14.5\n",
      "22.0\n",
      "20.0\n",
      "17.0\n",
      "21.0\n",
      "70.5\n",
      "29.0\n",
      "24.0\n",
      "2.0\n",
      "21.0\n",
      "24.0\n",
      "32.5\n",
      "32.5\n",
      "54.0\n",
      "12.0\n",
      "24.0\n",
      "24.0\n",
      "24.0\n",
      "45.0\n",
      "33.0\n",
      "20.0\n",
      "47.0\n",
      "29.0\n",
      "25.0\n",
      "23.0\n",
      "19.0\n",
      "37.0\n",
      "16.0\n",
      "24.0\n",
      "24.0\n",
      "22.0\n",
      "24.0\n",
      "19.0\n",
      "18.0\n",
      "19.0\n",
      "27.0\n",
      "9.0\n",
      "36.5\n",
      "42.0\n",
      "51.0\n",
      "22.0\n",
      "55.5\n",
      "40.5\n",
      "24.0\n",
      "51.0\n",
      "16.0\n",
      "30.0\n",
      "24.0\n",
      "24.0\n",
      "44.0\n",
      "40.0\n",
      "26.0\n",
      "17.0\n",
      "1.0\n",
      "9.0\n",
      "24.0\n",
      "45.0\n",
      "24.0\n",
      "28.0\n",
      "61.0\n",
      "4.0\n",
      "1.0\n",
      "21.0\n",
      "56.0\n",
      "18.0\n",
      "24.0\n",
      "50.0\n",
      "30.0\n",
      "36.0\n",
      "24.0\n",
      "24.0\n",
      "9.0\n",
      "1.0\n",
      "4.0\n",
      "24.0\n",
      "24.0\n",
      "45.0\n",
      "40.0\n",
      "36.0\n",
      "32.0\n",
      "19.0\n",
      "19.0\n",
      "3.0\n",
      "44.0\n",
      "58.0\n",
      "24.0\n",
      "42.0\n",
      "24.0\n",
      "24.0\n",
      "28.0\n",
      "24.0\n",
      "34.0\n",
      "45.5\n",
      "18.0\n",
      "2.0\n",
      "32.0\n",
      "26.0\n",
      "16.0\n",
      "40.0\n",
      "24.0\n",
      "35.0\n",
      "22.0\n",
      "30.0\n",
      "24.0\n",
      "31.0\n",
      "27.0\n",
      "42.0\n",
      "32.0\n",
      "30.0\n",
      "16.0\n",
      "27.0\n",
      "51.0\n",
      "24.0\n",
      "38.0\n",
      "22.0\n",
      "19.0\n",
      "20.5\n",
      "18.0\n",
      "24.0\n",
      "35.0\n",
      "29.0\n",
      "59.0\n",
      "5.0\n",
      "24.0\n",
      "24.0\n",
      "44.0\n",
      "8.0\n",
      "19.0\n",
      "33.0\n",
      "24.0\n",
      "24.0\n",
      "29.0\n",
      "22.0\n",
      "30.0\n",
      "44.0\n",
      "25.0\n",
      "24.0\n",
      "37.0\n",
      "54.0\n",
      "24.0\n",
      "29.0\n",
      "62.0\n",
      "30.0\n",
      "41.0\n",
      "29.0\n",
      "24.0\n",
      "30.0\n",
      "35.0\n",
      "50.0\n",
      "24.0\n",
      "3.0\n",
      "52.0\n",
      "40.0\n",
      "24.0\n",
      "36.0\n",
      "16.0\n",
      "25.0\n",
      "58.0\n",
      "35.0\n",
      "24.0\n",
      "25.0\n",
      "41.0\n",
      "37.0\n",
      "24.0\n",
      "63.0\n",
      "45.0\n",
      "24.0\n",
      "7.0\n",
      "35.0\n",
      "65.0\n",
      "28.0\n",
      "16.0\n",
      "19.0\n",
      "24.0\n",
      "33.0\n",
      "30.0\n",
      "22.0\n",
      "42.0\n",
      "22.0\n",
      "26.0\n",
      "19.0\n",
      "36.0\n",
      "24.0\n",
      "24.0\n",
      "24.0\n",
      "23.5\n",
      "2.0\n",
      "24.0\n",
      "50.0\n",
      "24.0\n",
      "24.0\n",
      "19.0\n",
      "24.0\n",
      "24.0\n",
      "0.92\n",
      "24.0\n",
      "17.0\n",
      "30.0\n",
      "30.0\n",
      "24.0\n",
      "18.0\n",
      "26.0\n",
      "28.0\n",
      "43.0\n",
      "26.0\n",
      "24.0\n",
      "54.0\n",
      "31.0\n",
      "40.0\n",
      "22.0\n",
      "27.0\n",
      "30.0\n",
      "22.0\n",
      "24.0\n",
      "36.0\n",
      "61.0\n",
      "36.0\n",
      "31.0\n",
      "16.0\n",
      "24.0\n",
      "45.5\n",
      "38.0\n",
      "16.0\n",
      "24.0\n",
      "24.0\n",
      "29.0\n",
      "41.0\n",
      "45.0\n",
      "45.0\n",
      "2.0\n",
      "24.0\n",
      "28.0\n",
      "25.0\n",
      "36.0\n",
      "24.0\n",
      "40.0\n",
      "24.0\n",
      "3.0\n",
      "42.0\n",
      "23.0\n",
      "24.0\n",
      "15.0\n",
      "25.0\n",
      "24.0\n",
      "28.0\n",
      "22.0\n",
      "38.0\n",
      "24.0\n",
      "24.0\n",
      "40.0\n",
      "29.0\n",
      "45.0\n",
      "35.0\n",
      "24.0\n",
      "30.0\n",
      "60.0\n",
      "24.0\n",
      "24.0\n",
      "24.0\n",
      "25.0\n",
      "18.0\n",
      "19.0\n",
      "22.0\n",
      "3.0\n",
      "24.0\n",
      "22.0\n",
      "27.0\n",
      "20.0\n",
      "19.0\n",
      "42.0\n",
      "1.0\n",
      "32.0\n",
      "35.0\n",
      "24.0\n",
      "18.0\n",
      "1.0\n",
      "36.0\n",
      "24.0\n",
      "17.0\n",
      "36.0\n",
      "21.0\n",
      "28.0\n",
      "23.0\n",
      "24.0\n",
      "22.0\n",
      "31.0\n",
      "46.0\n",
      "23.0\n",
      "28.0\n",
      "39.0\n",
      "26.0\n",
      "21.0\n",
      "28.0\n",
      "20.0\n",
      "34.0\n",
      "51.0\n",
      "3.0\n",
      "21.0\n",
      "24.0\n",
      "24.0\n",
      "24.0\n",
      "33.0\n",
      "24.0\n",
      "44.0\n",
      "24.0\n",
      "34.0\n",
      "18.0\n",
      "30.0\n",
      "10.0\n",
      "24.0\n",
      "21.0\n",
      "29.0\n",
      "28.0\n",
      "18.0\n",
      "24.0\n",
      "28.0\n",
      "19.0\n",
      "24.0\n",
      "32.0\n",
      "28.0\n",
      "24.0\n",
      "42.0\n",
      "17.0\n",
      "50.0\n",
      "14.0\n",
      "21.0\n",
      "24.0\n",
      "64.0\n",
      "31.0\n",
      "45.0\n",
      "20.0\n",
      "25.0\n",
      "28.0\n",
      "24.0\n",
      "4.0\n",
      "13.0\n",
      "34.0\n",
      "5.0\n",
      "52.0\n",
      "36.0\n",
      "24.0\n",
      "30.0\n",
      "49.0\n",
      "24.0\n",
      "29.0\n",
      "65.0\n",
      "24.0\n",
      "50.0\n",
      "24.0\n",
      "48.0\n",
      "34.0\n",
      "47.0\n",
      "48.0\n",
      "24.0\n",
      "38.0\n",
      "24.0\n",
      "56.0\n",
      "24.0\n",
      "0.75\n",
      "24.0\n",
      "38.0\n",
      "33.0\n",
      "23.0\n",
      "22.0\n",
      "24.0\n",
      "34.0\n",
      "29.0\n",
      "22.0\n",
      "2.0\n",
      "9.0\n",
      "24.0\n",
      "50.0\n",
      "63.0\n",
      "25.0\n",
      "24.0\n",
      "35.0\n",
      "58.0\n",
      "30.0\n",
      "9.0\n",
      "24.0\n",
      "21.0\n",
      "55.0\n",
      "71.0\n",
      "21.0\n",
      "24.0\n",
      "54.0\n",
      "24.0\n",
      "25.0\n",
      "24.0\n",
      "17.0\n",
      "21.0\n",
      "24.0\n",
      "37.0\n",
      "16.0\n",
      "18.0\n",
      "33.0\n",
      "24.0\n",
      "28.0\n",
      "26.0\n",
      "29.0\n",
      "24.0\n",
      "36.0\n",
      "54.0\n",
      "24.0\n",
      "47.0\n",
      "34.0\n",
      "24.0\n",
      "36.0\n",
      "32.0\n",
      "30.0\n",
      "22.0\n",
      "24.0\n",
      "44.0\n",
      "24.0\n",
      "40.5\n",
      "50.0\n",
      "24.0\n",
      "39.0\n",
      "23.0\n",
      "2.0\n",
      "24.0\n",
      "17.0\n",
      "24.0\n",
      "30.0\n",
      "7.0\n",
      "45.0\n",
      "30.0\n",
      "24.0\n",
      "22.0\n",
      "36.0\n",
      "9.0\n",
      "11.0\n",
      "32.0\n",
      "50.0\n",
      "64.0\n",
      "19.0\n",
      "24.0\n",
      "33.0\n",
      "8.0\n",
      "17.0\n",
      "27.0\n",
      "24.0\n",
      "22.0\n",
      "22.0\n",
      "62.0\n",
      "48.0\n",
      "24.0\n",
      "39.0\n",
      "36.0\n",
      "24.0\n",
      "40.0\n",
      "28.0\n",
      "24.0\n",
      "24.0\n",
      "24.0\n",
      "19.0\n",
      "29.0\n",
      "24.0\n",
      "32.0\n",
      "62.0\n",
      "53.0\n",
      "36.0\n",
      "24.0\n",
      "16.0\n",
      "19.0\n",
      "34.0\n",
      "39.0\n",
      "24.0\n",
      "32.0\n",
      "25.0\n",
      "39.0\n",
      "54.0\n",
      "36.0\n",
      "24.0\n",
      "18.0\n",
      "47.0\n",
      "60.0\n",
      "22.0\n",
      "24.0\n",
      "35.0\n",
      "52.0\n",
      "47.0\n",
      "24.0\n",
      "37.0\n",
      "36.0\n",
      "24.0\n",
      "49.0\n",
      "24.0\n",
      "49.0\n",
      "24.0\n",
      "24.0\n",
      "24.0\n",
      "44.0\n",
      "35.0\n",
      "36.0\n",
      "30.0\n",
      "27.0\n",
      "22.0\n",
      "40.0\n",
      "39.0\n",
      "24.0\n",
      "24.0\n",
      "24.0\n",
      "35.0\n",
      "24.0\n",
      "34.0\n",
      "26.0\n",
      "4.0\n",
      "26.0\n",
      "27.0\n",
      "42.0\n",
      "20.0\n",
      "21.0\n",
      "21.0\n",
      "61.0\n",
      "57.0\n",
      "21.0\n",
      "26.0\n",
      "24.0\n",
      "80.0\n",
      "51.0\n",
      "32.0\n",
      "24.0\n",
      "9.0\n",
      "28.0\n",
      "32.0\n",
      "31.0\n",
      "41.0\n",
      "24.0\n",
      "20.0\n",
      "24.0\n",
      "2.0\n",
      "24.0\n",
      "0.75\n",
      "48.0\n",
      "19.0\n",
      "56.0\n",
      "24.0\n",
      "23.0\n",
      "24.0\n",
      "18.0\n",
      "21.0\n",
      "24.0\n",
      "18.0\n",
      "24.0\n",
      "24.0\n",
      "32.0\n",
      "23.0\n",
      "58.0\n",
      "50.0\n",
      "40.0\n",
      "47.0\n",
      "36.0\n",
      "20.0\n",
      "32.0\n",
      "25.0\n",
      "24.0\n",
      "43.0\n",
      "24.0\n",
      "40.0\n",
      "31.0\n",
      "70.0\n",
      "31.0\n",
      "24.0\n",
      "18.0\n",
      "24.5\n",
      "18.0\n",
      "43.0\n",
      "36.0\n",
      "24.0\n",
      "27.0\n",
      "20.0\n",
      "14.0\n",
      "60.0\n",
      "25.0\n",
      "14.0\n",
      "19.0\n",
      "18.0\n",
      "15.0\n",
      "31.0\n",
      "4.0\n",
      "24.0\n",
      "25.0\n",
      "60.0\n",
      "52.0\n",
      "44.0\n",
      "24.0\n",
      "49.0\n",
      "42.0\n",
      "18.0\n",
      "35.0\n",
      "18.0\n",
      "25.0\n",
      "26.0\n",
      "39.0\n",
      "45.0\n",
      "42.0\n",
      "22.0\n",
      "24.0\n",
      "24.0\n",
      "24.0\n",
      "48.0\n",
      "29.0\n",
      "52.0\n",
      "19.0\n",
      "38.0\n",
      "27.0\n",
      "24.0\n",
      "33.0\n",
      "6.0\n",
      "17.0\n",
      "34.0\n",
      "50.0\n",
      "27.0\n",
      "20.0\n",
      "30.0\n",
      "24.0\n",
      "25.0\n",
      "25.0\n",
      "29.0\n",
      "11.0\n",
      "24.0\n",
      "23.0\n",
      "23.0\n",
      "28.5\n",
      "48.0\n",
      "35.0\n",
      "24.0\n",
      "24.0\n",
      "24.0\n",
      "36.0\n",
      "21.0\n",
      "24.0\n",
      "31.0\n",
      "70.0\n",
      "16.0\n",
      "30.0\n",
      "19.0\n",
      "31.0\n",
      "4.0\n",
      "6.0\n",
      "33.0\n",
      "23.0\n",
      "48.0\n",
      "0.67\n",
      "28.0\n",
      "18.0\n",
      "34.0\n",
      "33.0\n",
      "24.0\n",
      "41.0\n",
      "20.0\n",
      "36.0\n",
      "16.0\n",
      "51.0\n",
      "24.0\n",
      "30.5\n",
      "24.0\n",
      "32.0\n",
      "24.0\n",
      "48.0\n",
      "57.0\n",
      "24.0\n",
      "54.0\n",
      "18.0\n",
      "24.0\n",
      "5.0\n",
      "24.0\n",
      "43.0\n",
      "13.0\n",
      "17.0\n",
      "29.0\n",
      "24.0\n",
      "25.0\n",
      "25.0\n",
      "18.0\n",
      "8.0\n",
      "1.0\n",
      "46.0\n",
      "24.0\n",
      "16.0\n",
      "24.0\n",
      "24.0\n",
      "25.0\n",
      "39.0\n",
      "49.0\n",
      "31.0\n",
      "30.0\n",
      "30.0\n",
      "34.0\n",
      "31.0\n",
      "11.0\n",
      "0.42\n",
      "27.0\n",
      "31.0\n",
      "39.0\n",
      "18.0\n",
      "39.0\n",
      "33.0\n",
      "26.0\n",
      "39.0\n",
      "35.0\n",
      "6.0\n",
      "30.5\n",
      "24.0\n",
      "23.0\n",
      "31.0\n",
      "43.0\n",
      "10.0\n",
      "52.0\n",
      "27.0\n",
      "38.0\n",
      "27.0\n",
      "2.0\n",
      "24.0\n",
      "24.0\n",
      "1.0\n",
      "24.0\n",
      "62.0\n",
      "15.0\n",
      "0.83\n",
      "24.0\n",
      "23.0\n",
      "18.0\n",
      "39.0\n",
      "21.0\n",
      "24.0\n",
      "32.0\n",
      "24.0\n",
      "20.0\n",
      "16.0\n",
      "30.0\n",
      "34.5\n",
      "17.0\n",
      "42.0\n",
      "24.0\n",
      "35.0\n",
      "28.0\n",
      "24.0\n",
      "4.0\n",
      "74.0\n",
      "9.0\n",
      "16.0\n",
      "44.0\n",
      "18.0\n",
      "45.0\n",
      "51.0\n",
      "24.0\n",
      "24.0\n",
      "41.0\n",
      "21.0\n",
      "48.0\n",
      "24.0\n",
      "24.0\n",
      "42.0\n",
      "27.0\n",
      "31.0\n",
      "24.0\n",
      "4.0\n",
      "26.0\n",
      "47.0\n",
      "33.0\n",
      "47.0\n",
      "28.0\n",
      "15.0\n",
      "20.0\n",
      "19.0\n",
      "24.0\n",
      "56.0\n",
      "25.0\n",
      "33.0\n",
      "22.0\n",
      "28.0\n",
      "25.0\n",
      "39.0\n",
      "27.0\n",
      "19.0\n",
      "24.0\n",
      "26.0\n",
      "32.0\n"
     ]
    }
   ],
   "source": [
    "for i in train['Age']:\n",
    "    if b in train['Pclass']:\n",
    "        print(i/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.666666666666666]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Embarked']=lb.fit_transform(train['Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['PassengerId','Name','Ticket'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe=OneHotEncoder()\n",
    "train['Sex']=ohe.fit_transform(train['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0\n",
       "Pclass      0\n",
       "Sex         0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "Cabin       0\n",
       "Embarked    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Sex']=lb.fit_transform(train['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Cabin  Embarked\n",
       "0         0       3    1  22.0      1      0   7.2500     47         2\n",
       "1         1       1    0  38.0      1      0  71.2833     81         0\n",
       "2         1       3    0  26.0      0      0   7.9250     47         2\n",
       "3         1       1    0  35.0      1      0  53.1000     55         2\n",
       "4         0       3    1  35.0      0      0   8.0500     47         2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train['Survived']\n",
    "train.drop(['Survived'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOTUNRAYO OLUGBENGA\\Anaconda3\\New folder (2)\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\MOTUNRAYO OLUGBENGA\\Anaconda3\\New folder (2)\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train['Fare'][train['Fare']>60]=60\n",
    "train['Fare'][train['Fare']<2]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std=StandardScaler()\n",
    "X = std.fit_transform(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = pd.DataFrame(X, columns = dataset.columns)\n",
    "y=y.astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Feature Selection Algorithm (sbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SBS():\n",
    "    def __init__(self,estimator,k_features,scoring=accuracy_score,test_size=0.2,random_state=1):\n",
    "        self.scoring=scoring\n",
    "        self.estimator=clone(estimator)\n",
    "        self.k_features=k_features\n",
    "        self.test_size=test_size\n",
    "        self.random_state=random_state\n",
    "    def fit(self,X,y):\n",
    "        x_train,x_test,y_train,y_test= \\\n",
    "        train_test_split(X,y,test_size=self.test_size,random_state=self.random_state)\n",
    "        dim=x_train.shape[1]\n",
    "        self.indices_=tuple(range(dim))\n",
    "        self.subsets_=[self.indices_]\n",
    "        score=self._calc_score(x_train,y_train,x_test,y_test,self.indices_)\n",
    "        self.scores_=[score]\n",
    "        \n",
    "        while dim > self.k_features:\n",
    "            scores=[]\n",
    "            subsets=[]\n",
    "            \n",
    "            for p in combinations(self.indices_,r=dim-1):\n",
    "                score=self._calc_score(x_train,y_train,x_test,y_test,p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "                \n",
    "            best=np.argmax(scores)\n",
    "            self.indices_=subsets[best]\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim-=1\n",
    "            \n",
    "            self.scores_.append(scores[best])\n",
    "        self.k_score_=self.scores_[-1]\n",
    "        \n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return X[:,self.indices_]\n",
    "    \n",
    "    def _calc_score(self,x_train,y_train,x_test,y_test,indices):\n",
    "        self.estimator.fit(x_train[:,indices],y_train)\n",
    "        y_pred=self.estimator.predict(x_test[:,indices])\n",
    "        score=self.scoring(y_test,y_pred)\n",
    "        return score\n",
    "    \n",
    "\n",
    "            \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.neighbors import KNeignborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOTUNRAYO OLUGBENGA\\Anaconda3\\New folder (2)\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Ir=RandomForestClassifier()\n",
    "#lr=LogisticRegression()\n",
    "Ir.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fitting Sbs on RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sbs=SBS(Ir,k_features=1)\n",
    "sbs.fit(x_train,y_train)\n",
    "k_feat=[len(k)for k in sbs.subsets_]\n",
    "plt.plot(k_feat,sbs.scores_,marker='o')\n",
    "plt.ylim([0.7,1.02])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of features')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sex', 'Age', 'SibSp', 'Parch'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "k3=list(sbs.subsets_[4])\n",
    "print(train.columns[1:][k3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age\n",
       "SibSp      \n",
       "1      38.0\n",
       "1      38.0\n",
       "0      22.0\n",
       "1      38.0\n",
       "0      22.0\n",
       "...     ...\n",
       "0      22.0\n",
       "0      22.0\n",
       "1      38.0\n",
       "0      22.0\n",
       "0      22.0\n",
       "\n",
       "[891 rows x 1 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances=Ir.feature_importances_\n",
    "indices=np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Criterion and important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2=pd.DataFrame(train['Age'],train['SibSp'],train['Sex'],train['Parch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples that meet the criterion: 712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "sfm=SelectFromModel(Ir,threshold=0.1,prefit=True)\n",
    "X_selected=sfm.transform(x_train)\n",
    "print('Number of samples that meet the criterion:',X_selected.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_labels=train.columns[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) Age                            0.298182\n",
      " 2) SibSp                          0.227510\n",
      " 3) Cabin                          0.194139\n"
     ]
    }
   ],
   "source": [
    "for f in range (X_selected.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f+1,30,feat_labels[indices[f]],importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range (x_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f+1,30,feat_labels[indices[f]],importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Feature Importance')\n",
    "plt.bar(range(x_train.shape[1]),importances[indices],align='center')\n",
    "plt.xticks(range(x_train.shape[1]),feat_labels,rotation=90)\n",
    "plt.xlim([-1,x_train.shape[1]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1=pd.DataFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1.drop(['Fare','Parch','Embarked','Cabin'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "B=train1\n",
    "x_trai,x_tes,y_trai,y_tes=train_test_split(B,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOTUNRAYO OLUGBENGA\\Anaconda3\\New folder (2)\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "Lr=LogisticRegression(C=0.0001)\n",
    "Lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7668539325842697"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lr.score(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting leastcriterion for LogisticRegression"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "to be used in other pages then\n",
    "line 10 is weights.append(Lr.coef_[1])\n",
    "line 16 is label=train.columns[column + 1],color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure()\n",
    "ax=plt.subplot(111)\n",
    "colors=['blue','green','red','cyan','magenta','yellow','black','pink','lightgreen','lightblue','grey','indigo','orange']\n",
    "weights,params=[],[]\n",
    "for c in np.arange(-4.,6.):\n",
    "    Lr=LogisticRegression(penalty='l1',\n",
    "                          C=10.**c,\n",
    "                          random_state=0)\n",
    "    Lr.fit(x_train,y_train)\n",
    "    weights.append(Lr.coef_[0])\n",
    "    params.append(10**c)\n",
    "weights=np.array(weights)\n",
    "\n",
    "for column,color in zip(range(weights.shape[1]),colors):\n",
    "    plt.plot(params,weights[:,column],\n",
    "            label=train.columns[column],color=color)\n",
    "plt.axhline(0,color='black',linestyle='--',linewidth=3)\n",
    "plt.xlim([10**(-5),10**5])\n",
    "plt.ylabel('weight coefficient')\n",
    "plt.xlabel('C')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper left')\n",
    "ax.legend(loc='upper center',bbox_to_anchor=(1.38,1.03),ncol=1,fancybox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MOTUNRAYO OLUGBENGA\\Anaconda3\\New folder (2)\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Ir=RandomForestClassifier()\n",
    "#lr=LogisticRegression()\n",
    "Ir.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6292134831460674"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ir.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=Ir.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,precision_score,classification_report,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[92, 18],\n",
       "       [45, 24]], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6480446927374302"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7751937984496124"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train.drop(['Sex','Pclass','Fare','Parch','Embarked'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
